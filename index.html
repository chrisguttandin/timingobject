<!DOCTYPE html>
<html>
  <head>
    <title>Timing Object</title>
    <meta charset="utf-8">
    <script src="http://www.w3.org/Tools/respec/respec-w3c-common"
            async class="remove"></script>
    <script class="remove">
      var respecConfig = {
          specStatus: "ED",
          edDraftURI: "http://webtiming.github.io/timingobject",
          shortName:  "timing-object",
          editors: [
            {
              name:       "François Daoust",
              company:    "W3C",
              companyURL: "http://www.w3.org",
              mailto:     "fd@w3.org"
            }
          ],
          authors: [
            {
              name:       "Ingar M. Arntzen",
              company:    "Motion Corporation",
              companyURL: "http://motioncorporation.com/",
              mailto: "ingar.arntzen@motioncorporation.com"
            },
            {
              name:       "Njål T. Borch",
              company:    "Motion Corporation",
              companyURL: "http://motioncorporation.com/",
              mailto: "njaal.borch@motioncorporation.com"
            }
          ],
          wg:           "Multi-Device Timing Community Group",
          wgURI:        "http://www.w3.org/community/webtiming/",
          wgPublicList: "public-webtiming",

          localBiblio:  {
            "MSV": {
              title:    "The Media State Vector: A unifying concept for multi-device media navigation",
              href:     "http://motioncorporation.com/publications/mediastatevector2012.pdf",
              authors:  [
                "Ingar M. Arntzen",
                "Njål T. Borch",
                "Christopher P. Needham"
              ]
            }
        }
      };
    </script>
    <style type="text/css">
      table { border-collapse: collapse; border-style: hidden hidden none hidden; }
      table thead, table tbody { border-bottom: solid; }
      table td, table th { border-left: solid; border-right: solid; border-bottom: solid thin; vertical-align: top; padding: 0.2em; }
    </style>
  </head>
  <body>
    <section id="abstract">
      <p>
        This specification defines a timing object and an associated API. The timing object is a local object that may be used by Web clients to ensure precisely timed execution. If multiple time-sensitive components take direction from the same timing object, their behaviour will be precisely coordinated in time. Crucially, this is also the case in distributed settings. A central motivation for the timing object is that it may be connected to an online timing resource. This way, the local timing object is gateway to precisely timed operations, both in single-device as well as multi-device scenarios.
      </p>
      <p>
        Synchronized playback of multi-device linear media is an important use-case for multi-device timing. However, multi-device timing has wide utility for a variety of timing related challenges, including distributed media control and remote control, distributed synchronization, distributed time-shifting, distibuted time-ordering and distributed recording (time-stamping). The <a href="https://www.w3.org/community/webtiming/">W3C Multi-device Timing Community Group</a> works to extend the Web with support for multi-device timing, and the timing object is the central concept in this initiative.
      </p>

       <p>
        The design of the timing object has two main goals:
      </p>
      <ol>
        <li>
          provide a unifying API to which linear components may integrate in order to support linear composability. The API must support highly precise timing, and be expressive enough to support control primitives appropriate for a wide range of media types and applications.
        </li>
        <li> 
          encapsulate complexity of distributed time synchronization. In particular, by providing the same API for local and online timing resources, timing-sensitive components may be used in single-device and multi-device scenarios, without modification. 
        </li>
      </ol>
      
    </section>

    <section id="sotd">
      <p>
        The specification is intended for discussion within the Multi-Device Timing Community Group. Its content does not yet represent the consensus of the Community Group.
      </p>
    </section>
    
    <section class="informative">
      <h2>Introduction</h2>
      
      <p>
        Timing mechanisms allow operations to be executed at the correct time. The Web already has several mechanisms supporting timed operations, including setTimeout, setInterval, as well as controllers for media frameworks and animations. Unfortunately, these mechanisms are limited in scope, as they only apply to timed operations within a single web page. In contrast, a multi-device timing mechanism allows precisely timed operations across Web pages hosted by different devices. The W3C Multi-device Timing Community Group has been formed with the goal of extending the Web with native support for precisely timed operation in the multi-device scenario.
      </p>
      
      <p>
        Multi-device timing is key to solving a variety of timing related challenges across a wide range of application domains. For example, this would include multi-device production and consumption of music, live, collaborative time-sensitive Web productions, Web-based secondary device applications with time-shifting capabilities, multi-screen systems, collatorative viewing, remote Web-based presentations, distributed remote controlling, multi-device time-senstive recording (time-stamping) with time-shifted multi-screen replay, and probably a lot more.
      </p>


      <b>Linear Composition</b>
      <p>
        Multi-device timing has particular importance for multi-device, linear media, as it is key to distributed, time-sentitive playback. Here we express the motivation of the timing object specifically in the context of linear media. So, an important purpose of introducing the timing object into HTML is to enable <i>linear composition</i> in both single-device and multi-device linear media. 
      </p>

      <p>
        Linear composition is simply the idea that complex linear media could be built from simpler, independent linear components. This way, the classical benefits of composition as a design principle, i.e., flexibility, reusability, extensibilty and mashup-ability, would fully apply to linear media. For example, in the single-device scenario, imagine a linear presentation made from HTML5 video, some timed meta-information, a SMIL component, a WebAnimation, a map with timed georeferenced data, and a timed Twitter widget. Or, in the multi-device scenario, imagine the same components distributed or duplicated across multiple devices. In both cases linear composition require interoperability of heterogeneous linear components, through precisely coordinated, timed playback. Currently there is weak support for this, and a main reason for this is that timing control mechanisms are custom, and internal to each framework. This central purpose of the timing object is thus to simplify interoperability by providing a common basis for timing control in linear media.  
      </p>

      <p>
       For a more extensive introduction to linear composition, please consult documentation on the <a href="https://www.w3.org/community/webtiming/">W3C Multi-device Timing Community Group</a>.
      </p>


      <b>Design Goals and Architecture</b>
      <p>
        The design of the timing object has two main goals:
      </p>
      <ol>
        <li>
          provide a unifying API to which linear components may integrate in order to support linear composability. The API must support highly precise timing, and be expressive enough to support control primitives appropriate for a wide range of media types and applications.
        </li>
        <li> 
          encapsulate complexity of distributed time synchronization. In particular, by providing the same API for local and online timing resources, timing-sensitive components may be used in single-device and multi-device scenarios, without modification. 
        </li>
      </ol>
     
      <p>
        The figure below illustrates these functions, as well as the underlying client-server architecture. Three devices each have a single HTMLTimingObjects, which are then individually connected to a single, shared online timing resource. Internally on each device, the HTMLTimingObject will act as the director for independent, time-sensitive GUI components. This way, a video will aim to present videoframes in accordance with the HTMLTiming resource. Similarly, a time-sensitive Twitter widget might replay time-stamped Twits. If the HTMLTimingObject pauses, the connected components are notified and react accordingly. Crucially, note how the different components can go about their business in complete isolation. There is no need for components to communicate, except indirectly through the HTMLTimingObject. This loose coupling is the key to linear compsability.
      </p>
      <p>
        Furthermore, when HTMLTimingObjects are connected to an online timing resource, they will act as local representatives. For example, if a connected HTMLTimingObject is requested to pause, the request will simply be forwarded to the online timing object. As the online object pauses, notifications will be multicast to all connected clients. Finally, HTMLTimingObject will update their internal state and notify connected UI components. For online timing objects, clients can expect update latency of about 1 RTT (TCP), whereas local timing resources should have no update latency. Apart from this, online and local timing resources should be hard to distinguish. Note also that the argument made for the independence of time-sensitive components in the single-device scenario now applies to the multi-device scenario as well. 
      </p>

      <p class="note">
        The protocol used to connect, synchronize and interact with online timing resources will be defined in a separate specification.
      </p>
      <p class="note">
        Similarly, the integration of the timing object with UI components such as HTML5 Media Elements and HTML5 Track Elements [[HTML5]] will be covered in a separate specification.
      </p>
 

      <figure>
        <img src="overview.png" width="400" alt="The image illustrates the concept of an online timing resource how it used to synchronize HTTPTimingObjects across three different Web clients." />
        <figcaption>HTMLTimingObjects at three devices connected to a single, shared online timing resource.</figcaption>
      </figure>

     
      <b>HTMLTimingObject</b>
      <p>
        The HTMLTimingObject is conceptually a very simple object, essentially an advanced stop watch. If started, its value changes predictably in time, until at some point later, it is paused, or perhaps reset. It may be queried for its value at any time. For example, it should take exactly 2.0 seconds for the value of to advance from 3.0 to 5.0, given that the velocity is 1.0. Such deterministic behavior is required for reliable distributed synchronization. In terms of implementation, the HTMLTimingObject is a fairly thin wrapping around the system clock. (Integration with online timing resources adds a bit of complexity). Since it is based on the system clock, the HTMLTimingObject supports the same resolution and predictability as the system clock. This makes the HTMLTimingObject a sound basis for precise timing.
      </p>
      <p>
        Importantly, the HTMLTimingObject is more expressive than the traditional stop watch. It supports any velocity or acceleration, and may jump to any position on the timeline. In fact, the HTMLTimingObject essentially implements linear motion along a unidimensional axis. An elegant implementation is provided by the concept of Media State Vectors (MSV), based on the classical equations of linear motion under constant acceleration. The HTMLTimingObject adopts this model. At any point in time, position, velocity or acceleration may be requested to change. Querying the HTMLTimingObject reveals not only its current value (position) but also its velocity and acceleration at that moment. This detailed information is again helpful in precise synchronisation, and the expressiveness of the underlying mathematical model implies that a wide variety of control primitives may be supported. In particular, discrete jumps on the timeline may be used to control a slide show, whereas velocity corresponds to playbackRate for the control of continuous media. Acceleration is required by certain animation frameworks.
     </p>
     <p>
        We are not the first to define timing controls for linear media. Similar constructs have been explored in both academia and industry from the 70'ies and onwards.Indeed, any framework for linear media would maintain similar constructs internally. Instead, the novelty is to represent timing as an explicit resource on the Web, independent of framework, thereby creating a basis for interoperability. Also, integration with server-hosted, online timing resources is a novelty.
      </p>     

      <figure>
        <img src="stopwatch_digital.jpg" width="80" alt="The HTMLTimingObject is essentially and advanced stop watch." />
        <figcaption>The HTMLTimingObject is essentially an advanced stop watch.</figcaption>
      </figure>
        <figure>
        <img src="timeline.png" width="400" alt="The HTMLTimingObject is essentially and advanced stop watch." />
        <figcaption>The HTMLTimingObject visualized as a cursor moving along a timeline.</figcaption>
      </figure>

      <b>Programming with HTMLTimingObjects</b>

      <p>
        Timing objects are resources used by your application, and you may define as many as you like. What purposes they serve in the application is up to the programmer. If the application needs a shared, multi-device clock, just start a timing object and make sure you never stop it. If you want the clock value to represent milliseconds, just set the velocity to 1000 (advances the timingobject with 1000 milliseconds per second). If the timing object represents media offset, just specify the playback position, the velocity, and perhaps a media duration. For video you might measure offset in seconds or frames and set the velocity accordingly. Or, for musical applications it may be practical to let the timing object represent beats per second. Note also that the timing object may represent time-changes with any kind of variable. For instance, if you have data that is organized according to, say height above sea level, you may want to animate how this data changes as you move vertically. In this case the timing object might represent meters or feet above earth, and positive and negative velocities would allow you to move both upwards and downwards.
      </p>
      <p>
        In general, the timing object is particularly useful when you have a variable that needs to change predictably in time. You may of course achieve this simply by overwriting a value repeatedly in time (this is essentially the approach of the current HTMLMediaElement), but the timing object provides an improvement on this approach, particularly with respect to precise synchronization.
      </p>
    


      <!--
      <p>
        <a href="#fig-multi-device-synchronization-architecture"></a> illustrates three Web clients hosted by three different devices, say a laptop, a smartphone and a tablet. These three Web clients each have a timing object connected to a single, online, multi-device timing resource. For example, the online timing resource could be used as basis for shared media control, allowing multiple clients to operate in synchrony. This way, a laptop could present a video, the smartphone could present the audio track, and the tablet could present controls, progressbar, and timed extra information. If the timing resource is requested to pause, all connected clients pause in unison.
      </p>
      -->


    </section>

    <section class="informative">
      <h2>Use cases and requirements</h2>
      <p>
        Precise timing has wide applicabilty in both single-device and multi-device applications. Here we identify some common use cases.
      </p>

      <ol>

      <li>
      <b> Collaborative Viewing and Media Control</b>
      <p>
        Allow people to enjoy the same content at the same time. Alice and Bob might watch the next episode together, even if Alice is on a train and Bob stays at home. If Alice pauses the video while briefly speaking with the conductor, Bob's video pauses too. Alice and Bob may always trust the other to see the exact same thing, making it very easy for them to maintain a conversation using a chat service or a phone service. It would also be possible for Alice and Bob to split part temporarily. Alice would see Bob moving along the progress line without her, and Bob would see Alice staying behind. When Alice is ready to resume viewing a bit later, she may continue on her own, play doublespeed or skip to catch up with Bob, or convice Bob to wait for her or jump back to see the segment again with her.      
      </p>
      <p>
        This use case is based on <a href="http://www.w3.org/2011/webtv/wiki/New_Ideas">UC2-3 Identical Media Stream Synchronization</a>, a usecase defined by the <a href="http://www.w3.org/2011/webtv/">W3C Web and TV InterestGroup</a>
      </p>
      <p>
        This use case requires the management and sharing of multiple timing objects, at least one for Alice and one for Bob. Precision requirements for video synchronization are quite coarse as the use case is described. However, Alice and Bob might also choose to use this application in circumstances where they are sitting next to eachother, or they might hook their devices on to projectors in order to show a movie to a larger audience. Sub-framerate precision is required in order to avoid echo from device speakers. 
      </p>
      </li>

      <li>
      <b> Time-consistent, Live Web Productions </b>
      <p>
        The BBC provides live coverage of popular sport events such the FIFA World Cup. Modern Web presentations of this kind tend to include many independent media streams. For example, there might be multiple video streams for different camera angles, there are visualization of players on the field, player statitistics, and there might be commentary from studio as well as viewers. Earlier, Bob was annoyed that user comments could sometimes ruin the experience by shouting GOAL!  20 seconds before the goal appeared in the video stream. However, after BBC started timeshifting live Web content to match distribution latency in the video backend, this problem seems to be a thing of the past.
      </p>
      <p>
        This requires figuring out the estimated latency of the slowest media stream, and then to define a timing resource from which all parts of a presentation takes direction. In effect, early spoilers will be delayed (buffered) by the Web browsers and applied at the correct point in time.
      </p>
      </li>

      <li>
      <b> Time-shifted, Live Web productions </b>
      <p>
        A commercial media provider offers live Web content supplementing live broadcast of F1 races. Sometimes, as F1 races are held in different time zones, the provider will re-broadcast nighly races in the morning. As a keen F1 enthusiast, Alice is discontent that the Web content can not be time-shifted along with the re-broadcast of the race. So is Bob, head of marketing with the media provider, as he would like to sell time sensitive, Web-based ads for F1 races, and have the ads be presented correct for both live and time-shifted broadcasts, as well as later on demand viewers.  
      </p>
      <p>
        This requires timestamping of live Web production so that is may be time-shifted correctly and aligned with a time-shifted broadcast.
      </p>
      </li>

      <li>
      <b> Timed, Web-based Secondary Device </b>
      <p>
        Alice opens the BBC Sport Web page on her iPad during the olympic games. The backend service consults Alice's profile and learns that she is already watching figure skating from the iPlayer on her laptop computer. As a result, the BBC Sports Web page is personalized with an offer to load BBC's Web-based extra material for figure skating. Alice accepts, and the iPad goes on to present stats, images, infographics, commentary and alternative camera angles, all precisely timed with the iPlayer. Alice notises that other viewers have already highlighted a chinese athlete performing a bit earlier. She clicks to see it, and both the iPlayer (on the laptop) and the timed Web presentation (on the iPad) immediately skips back. After having seen the athlete's performance, now with added commentary provided by excited viewers, Alice contributes by giving it a thumbs up, and then clicks the back-to-live button. Both the laptop and the iPad snaps back to presenting the live action.
      </p>
      <p>
        This use case is based on <a href="http://www.w3.org/2011/webtv/wiki/New_Ideas">UC2-4 Related Media Stream Synchronization</a>, a usecase defined by the <a href="http://www.w3.org/2011/webtv/">W3C Web and TV InterestGroup</a>
      </p>
      <p>
        This use case requires managing personal timing resources for individual viewers, as well as a common timing resource representing the live clock. Both iPlayer and Web-based secondary device offerings must take direction from online timingresources, and allow dynamic switching of timing objects based on user input. Presenting alternative camera angles as part of secondary device offerings require precise synchronization.   
      </p>
      </li>


      <li>
      <b> Timed, Multi-device Web Presentations </b>
      <p>
        Alice teaches an online course for international students from across the globe. Every week she goes through a new Web-based slide set. Just before the session, she makes two links available for her students on the class Web page, links for the primary and the secondary view of the presentation. When the time is there she connects on an audio link and requests the first slide to be presented. Slides are presented on her view and on all the views of her connected students, at exactly the same time. This way, Alice can be sure what she said on the audio link is always backed up with the correct illustrations. In effect, Alice remotely controls the Web browsers of all her students. Alice also has included a video in on of the slides. She plays the video for all the studends on the primary view, while presenting some related bullet points on the secondary view. Alice pauses the video at a certain point in order to highligh an important aspect. Beforehand she has prepared some bookmarks in the video, allowing her to effectively skip to the interesting parts. At some point one of the student has a question related to the movie. Alice temporarily gives the student access to control the video, and the student revinds it to explain the source of his question. Afterwards, Alice withdraws the controls from the student and continues. The entire event is recorded and timestamped, allowing students that missed the class to replay the audio with and the slide presentation precisely as it was given. This review also provides synchronized presentations of student comments as well as text-based search capabilities.         
      </p>
      <p>
        Multi-device slide show navigation requires a single shared timing resource, where position represents slide number. Videos require additional timing resources. Finally, timestamping of audio, slide navigation, video navigation, students commentary etc., requires an addition timing resource as shared clock.
      </p>
      </li>


      <li>
      <b> Timed, Multi-screen Web Presentations </b>
      <p>
        Bob is heading a research project responsible for collecting and presenting a variety of data series related to climate changes in the Arctic. Web-based visualizations makes for a very dynamic and extensible visualization system. Multiple screens may be used to present and aligne very different timed visualizations, making it easier to detect visible patterns and possible correlations. The different visualizations may be navigated in unison. For instance, Bob may slow down the presentation for the heavy melting days to co-present this with measurements of salinity levels in the seawater. Bob may also search his data to find the day with the highest temperature. By clicking on the result, all screens immediately displays the relevant data for that day. 
        Alice is recognized as an international expert in this area. Bob shares the link with Alice in an email, they may co-view the presentation even though they are stationed in different continents, and Alice may explore the visualization herself before giving her opinion. 
      </p>
      <p>
        A shared timing resource is required to support playback of timed data streams on multiple screens. The utility is not limited to Web-based visualization. For instance, native visualization frameworks may also interact with multi-device timing resources, thus enabling very different visualization systems to cooperate in presenting a common data model. 
      </p>
      </li>



      <li>
      <b> Device Migration </b>
      <p>
        Bob is watching a Netflix show using Chromecast on the TV when Alice interrupts and demands access to the living room big screen for herself and her friends. Bob reluctantly agrees to finish the show in his bedroom. Before he gets up he opens Netflix on his iPad. Netflix, well aware that Bob is already actively watching something, defaults to present the exact same thing, in perfect synchrony with the TV. Ensured that the transition was smooth, Bob leaves for his bedroom while staring at his iPad.      
      </p>
      <p>
        The use case requires online timing resources and content resources to be tied to login information. So, when an already logged in user enters a VoD service with a second device, the default action could be to resolve which show is already playing and what timing resource is being used, and then to set up the new view with the exact same resources. 
      </p>
      </li>


      <li>
      <b> Alternative Soundtracks </b>
      <p>
        Alice's Portuguise mother has a hairing deficiency, so as the two of them sit down to watch a movie together, Alice hooks her smart phone up with the Portuguise audio track and lets her mother adjust the sound volume.
      </p>
      <p>
        This use case is based on <a href="http://www.w3.org/2011/webtv/wiki/New_Ideas">UC2-6 Clean Audio</a>, a usecase defined by the <a href="http://www.w3.org/2011/webtv/">W3C Web and TV InterestGroup</a>
      </p>
      <p>
        This requires lip-synch presicion between video and audio. 
      </p>
      </li>


      <li>
      <b> Timing Interoperability between Independent Providers </b>
      <p>
        Bob watches soccer. Unfortunately, the clueless commentator is constantly pissing him off as he clearly favoures the other team. Bob turns to a dedicated Web radio channel for an alternative commentator. The new commentator is better, but he is out of sync. Bob chooses the SyncWith option in the radio channel Web page and selects his TV provider. After confirming his credentials, the radio channel Web page is able to connect to the same timing resource used by the TV provider, and the Web radio is immediately in sync with his TV.
      </p>
      <p>
        This use case requires media providers to give access to timing resources associated with a given user, also when that user is requesting access from an external service. Synchronization of audio and video requires lip-synch precision.
      </p>
      </li>
 

      <li>
      <b> Linear Content Adaption </b>
      <p>
        Bob's watching cricket, but he and Alice soon needs to get in the car to start the long drive to visit Bob's parents. He would like to keep following the cricket game on his smart phone, but does not have the bandwidth nor the money to enjoy HD content. Instead, Bob selects the timed HTML option. The audio goes on undisturbed, but the HD video is immediately terminated and replaced with a light-weight, timed animations of the cricket field. Alice is behind the wheels, and Bob's may continue the cricket match through audio and all the secondary information. 
      </p>
      <p>
        Shared timing resources allow smooth and dynamic switching from HD to timed-based HTML.   
      </p>
      </li>

      <li>
      <b> Distributed Recording and Replayability </b>
      <p>
        use case ...
      </p>
      <p>
        requirements ...
      </p>
      </li>

      <li>
      <b> Distributed Music Production and Plaback  </b>
      <p>
        use case ...
      </p>
      <p>
        requirements ...
      </p>
      </li>

      <li>
      <b> Time sensitive Interactive Commercials </b>
      <p>
        use case ...
      </p>
      <p>
        requirements ...
      </p>
      </li>

      </ol>





    </section>

    <section id="conformance">
      <p>
        Requirements phrased in the imperative as part of algorithms (such as "strip any leading space characters" or "return false and terminate these steps") are to be interpreted with the meaning of the key word ("must", "should", "may", etc.) used in introducing the algorithm.
      </p>

      <p>
        Conformance requirements phrased as algorithms or specific steps may be implemented in any manner, so long as the end result is equivalent. (In particular, the algorithms defined in this specification are intended to be easy to follow, and not intended to be performant).
      </p>

      <p>
        This specification defines conformance criteria that apply to a single product: the <dfn>user agent</dfn> that implements the interfaces that it contains.
      </p>
    </section>

    <section>
      <h2>Terminology</h2>

      <p>
        The terms <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#event-handlers">event handler</a></dfn> and <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#event-handler-event-type">event handler event type</a></dfn> are defined in [[!HTML5]].
      </p>

      <p>
        The <dfn><code><a href="http://www.w3.org/TR/dom/#event">Event</a></code></dfn> interface represents an event as defined in [[!DOM]].
      </p>

      <p>
        The <code><a href="http://dev.w3.org/html5/spec/webappapis.html#eventhandler">EventHandler</a></code> interface represents a callback used for <a title="event handler">event handlers</a> as defined in [[!HTML5]].
      </p>

      <p>
        The <dfn><code><a href="http://dev.w3.org/html5/spec/webappapis.html#timeranges">TimeRanges</a></code></dfn> interface represents a list of ranges (periods) of time as defined in [[!HTML5]].
      </p>

      <p>
        The concepts <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#queue-a-task">queue a task</a></dfn>, <dfn><a href="http://dev.w3.org/html5/spec/webappapis.html#fire-a-simple-event">fires a simple event</a></dfn>, <dfn><a href="http://www.w3.org/html/wg/drafts/html/master/semantics.html#normalised-timeranges-object">normalised <code>TimeRanges</code> object</a></dfn> are defined in [[!HTML5]].
      </p>

      <p>
        An <dfn>online timing resource</dfn> is an object identified by a URL and by a timing service that represents various application-level timing concepts, such as clocks, timeouts, stop-watches or media controllers. Timing resources are created and used by Web applications in order to support timing-sensitive execution in multi-device applications.
      </p>

      <p>
        This document provides interface definitions using the [[!WEBIDL]] standard.
      </p>
    </section>

    <section class="informative">
      <h2>Example</h2>
      <p class="issue">
        Show how the timing object and API can be used in practice in a simple multi-device scenario. The example should demonstrate how to make use of main methods such as <code>query</code>, <code>update</code> and <code>getState</code>.
      </p>
      <pre class="example highlight">
        @@
      </pre>
    </section>

    <section>
      <h2>Timing objects</h2>

      <p>A <dfn>timing object</dfn> represents an ideal clock that advances deterministically in accordance with a local or online system clock.</p>

      <p>
        A <a>timing object</a> has an <dfn>internal motion</dfn> represented by a <a>media state vector</a>, which must initially be set to <code>(p<sub>0</sub>, v<sub>0</sub>, a<sub>0</sub>, t<sub>0</sub>)</code> where <code>p<sub>0</sub>=0.0</code>, <code>v<sub>0</sub>=0.0</code>, <code>a<sub>0</sub>=0.0</code> and where <code>t<sub>0</sub></code> is the local timestamp when the object is created.
      </p>

      <p>
        A <a>timing object</a> maintains an <dfn>internal synchronization state</dfn> that contains an estimate of the current client's clock skew relative to the online timing service when the object is associated with an <a>online timing resource</a>, as well as an estimate of the current network latency between the client and the online timing service. This information is used to correct timestamp values when <a title="media state vector">media state vectors</a> are exchanged between the client and the timing service. The user agent must initialize the skew and latency to 0.0. If the <a>timing object</a> is not associated with an online timing service, the skew and latency remain at 0.0.
      </p>

      <p><a title="timing object">Timing objects</a> implement the following interface:</p>

      <dl title="interface Timing : EventTarget" class="idl">
        <dt>Constructor()</dt>
        <dd>When the constructor is invoked, the user agent must <a>create a new timing object</a>.</dd>

        <dt>attribute DOMString src</dt>
        <dd>On getting, return the URL of the <a>online timing resource</a> associated with the object if there is one, null if the object uses the local clock. On setting, the user agent must invoke the <a>online timing resource load algorithm</a>.</dd>

        <dt>readonly attribute unsigned short readyState</dt>
        <dd><span class="issue">uses HTMLMediaElement.readyState's values?</span></dd>

        <dt>readonly attribute TimeRanges seekable</dt>
        <dd>A <a>normalised <code>TimeRanges</code> object</a> that represents the intersection of the ranges that the timing element may seek to.
        <br/><span class="issue">Only one element in the TimeRanges object?</span></dd>

        <dt>readonly attribute unrestricted double duration</dt>
        <dd>The timing object duration, if defined.<br/><span class="issue">linked to seekable?</span></dd>

        <dt>attribute double currentTime</dt>
        <dd>On getting, the user agent must <a>compute the position</a> at the current local time and return that value. On setting, the user agent must invoke the <code>update</code> method of the <a>Timing</a> object with parameters <code>(value, null, null)</code> where <code>value</code> it the new value. The user agent must interpret the new value as being in seconds.</dd>

        <dt>readonly attribute boolean paused</dt>
        <dd>true if the timing object is a paused timing object, and false otherwise.
        <br/><span class="issue">Define "paused timing object" properly</span></dd>

        <dt>attribute double playbackRate</dt>
        <dd>On getting, the user agent must <a>compute the velocity</a> at the current local time and return that value. On setting, the user agent must invoke the <code>update</code> method of the <a>Timing</a> object with parameters <code>(null, value, null)</code> where <code>value</code> is the new value.</dd>

        <dt>attribute EventHandler onplay</dt>
        <dd>Corresponds to the <a>play</a> <a>event handler event type</a>.</dd>

        <dt>attribute EventHandler onpause</dt>
        <dd>Corresponds to the <a>pause</a> <a>event handler event type</a>.</dd>

        <dt>attribute EventHandler onvectorchange</dt>
        <dd>Corresponds to the <a>vectorchange</a> <a>event handler event type</a>.</dd>

        <dt>attribute EventHandler onreadystatechange</dt>
        <dd>Corresponds to the <a>readystatechange</a> <a>event handler event type</a>.</dd>

        <dt>attribute EventHandler ontimeupdate</dt>
        <dd>Corresponds to the <a>timeupdate</a> <a>event handler event type</a>.</dd>

        <dt>void update (optional double? position, optional double? velocity, optional double? acceleration, optional Object? options)</dt>
        <dd>
          When called, the user agent must <a>update the internal motion</a> to the provided parameters, at the time when the update operation is processed. The parameters for the update operation are optional, i.e., null values may be supplied. This provides a simple mechanism for tying movements together. The idea is to allow one aspect of the movement to be updated while preserving the others. For instance, <code>update(null, value, null)</code> means "update velocity while preserving position and acceleration". Note that the values we want to preserve are not from the internal state, but rather from a snapshot of the <a>MediaStateVector</a> that represents the <a>internal motion</a>, taken at exactly the time when the update is processed.

          <dl class="parameters">
            <dt>optional double? position</dt>
            <dd>The new position, or null to preserve the current value at the time the update is processed.</dd>
            <dt>optional double? velocity</dt>
            <dd>The new velocity, or null to preserve the current value at the time the update is processed.</dd>
            <dt>optional double? acceleration</dt>
            <dd>The new acceleration, or null to preserve the current value at the time the update is processed.</dd>
          </dl>
        </dd>

        <dt>MediaStateVector query ()</dt>
        <dd>When invoked, the user agent must <a>compute the motion</a> at the current local time and return the result.</dd>

        <dt>TimingInfo getState ()</dt>
        <dd>When invoked, the user agent must return a <a>TimingInfo</a> object initialized with the latest known <a>internal synchronization state</a>.</dd>

        <dt>void pause ()</dt>
        <dd>When invoked, the user agent must invoke the <code>update</code> method of the <a>Timing</a> object with parameters <code>(null, 0.0, null)</code>. The update effectively causes the motion to stop.</dd>

        <dt>void play ()</dt>
        <dd>When invoked, the user agent must invoke the <code>update</code> method of the <a>Timing</a> object with parameters <code>(null, 1.0, null)</code>. The update effectively causes the motion to play at the usual playback rate.</dd>
      </dl>

      <section>
        <h3>Events</h3>

        <p>The following events fire on <a>Timing</a> objects:</p>

        <table>
          <thead>
            <tr>
              <th>Event name</th>
              <th>Interface</th>
              <th>Fired when...</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><dfn><code>play</code></dfn></td>
              <td><a><code>Event</code></a></td>
              <td>The <code>paused</code> attribute is newly false.</td>
            </tr>
            <tr>
              <td><dfn><code>pause</code></dfn></td>
              <td><a><code>Event</code></a></td>
              <td>The <code>paused</code> attribute is newly true.</td>
            </tr>
            <tr>
              <td><dfn><code>vectorchange</code></dfn></td>
              <td><a><code>Event</code></a></td>
              <td>The <a>internal motion</a> changed. Fired after the <code>update()</code> method has returned, or when an update is received from the <a>online timing resource</a>.</td>
            </tr>
            <tr>
              <td><dfn><code>readystatechange</code></dfn></td>
              <td><a><code>Event</code></a></td>
              <td>The <code>readyState</code> attribute changed.<br/><span class="issue">Split into different events?</span></td>
            </tr>
            <tr>
              <td><dfn><code>timeupdate</code></dfn></td>
              <td><a><code>Event</code></a></td>
              <td>The current position changed as part of current motion or in an especially interesting way, for example discontinuously.</td>
            </tr>
          </tbody>
        </table>
      </section>
    </section>

    <section>
      <h2>Media state vectors</h2>

      <p>
        A <dfn>media state vector</dfn> is a representation of uni-dimensional motion in real time, intended as a general basis for synchronization of distributed media presentations. See [[MSV]] for details about the underlying concepts of a media state vector.
      </p>

      <p><a title="media state vector">Media state vectors</a></code> implement the following interface, but note that they may be represented as quadruples <code>(position, velocity, acceleration, timestamp)</code> in other sections of this specification to improve readability:</p>

      <dl title="interface MediaStateVector" class="idl">
        <dt>readonly attribute double position</dt>
        <dd>The current position on the uni-dimensional axis.</dd>

        <dt>readonly attribute double velocity</dt>
        <dd>The current velocity along the uni-dimensional axis.</dd>

        <dt>readonly attribute double acceleration</dt>
        <dd>The current acceleration along the uni-dimensional axis.</dd>

        <dt>readonly attribute double timestamp</dt>
        <dd>The timestamp at the client clock when the position and velocity are evaluated.</dd>
      </dl>
    </section>

    <section>
      <h2>TimingInfo object</h2>

      <p>The <a>TimingInfo</a> object gives information about the internal state of a <a>timing object</a> at the time when <code>getState</code> is called.</p>

      <dl title="interface TimingInfo" class="idl">
        <dt>readonly attribute TimeRanges seekable</dt>
        <dd>A <a>normalised <code>TimeRanges</code> object</a> that represents the intersection of the ranges that the timing element may seek to.
        <br/><span class="issue">Why repeat that information here? It's available through the timing object already</span></dd>

        <dt>readonly attribute double skew</dt>
        <dd>Clock skew relative to the timing service.</dd>

        <dt>readonly attribute double latency</dt>
        <dd>Latency to timing service.</dd>

        <dt>readonly attribute unsigned short readyState</dt>
        <dd><br/><span class="issue">That's part of the state, but why repeat that information here? It's available through the timing object already</span></dd>

        <dt>readonly attribute boolean readonly</dt>
        <dd>Returns true when the timing object is read-only, false if the client can control the timing object. Calling the <code>update</code> method on a read-only timing object has no effect.</dd>

        <dt>readonly attribute MediaStateVector lastVector</dt>
        <dd>The initial vector that was before.
        <br/><span class="issue">Wouldn't previousVector be better?</span></dd>

        <dt>readonly attribute MediaStateVector vector</dt>
        <dd>The initial vector of the current timing.
        <br/><span class="issue">The use of "initial" is confusing. More the "latest" vector?</span></dd>
      </dl>
    </section>

    <section>
      <h2>Algorithms</h2>

      <section>
        <h3>Create a new timing object</h3>
        <p>
          When the user agent is required to <dfn>create a new timing object</dfn>, it must run the following steps:
        </p>
        <ol>
          <li>Let <em>timing</em> be a newly constructed <code><a>Timing</a></code> object.</li>
          <li>Initialize <em>timing</em>'s <a>internal motion</a> to <code>(0.0, 0.0, 0.0, t)</code> where <code>t</code> is the local timestamp in seconds when the object is created</li>
          <li>Initialize the skew and latency of <em>timing</em>'s <a>internal synchronization state</a> to 0.0.</li>
          <li>Initialize <em>timing</em>'s <code>readyState</code> to <code>HAVE_NOTHING</code>.</li>
          <li>Initialize <em>timing</em>'s <code>paused</code> attribute to true.</li>
          <li>Return <em>timing</em>.</li>
        </ol>

      <section>
        <h3>Compute the position</h3>
        <p>
          When the user agent is required to <dfn>compute the position</dfn> at a given time <code>t</code>, it must run the following steps:
        </p>
        <ol>
          <li><span class="issue">TODO: deal with initialisation conditions (readyState, Media State Vector)</span></li>
          <li>Let <code>(p<sub>i</sub>, v<sub>i</sub>, a<sub>i</sub>, t<sub>i</sub>)</code> represent the current <a>internal motion</a></li>
          <li>Let <em>pos</em> be <code>p<sub>i</sub> + v<sub>i</sub> (t - t<sub>i</sub>) + 1/2 a<sub>i</sub> (t - t<sub>i</sub>)<sup>2</sup></code></li>
          <li>Return <em>pos</em></li>
        </ol>
      </section>

      <section>
        <h3>Compute the velocity</h3>
        <p>
          When the user agent is required to <dfn>compute the velocity</dfn> at a given time <code>t</code>, it must run the following steps:
        </p>
        <ol>
          <li><span class="issue">TODO: deal with initialisation conditions (readyState, Media State Vector)</span></li>
          <li>Let <code>(p<sub>i</sub>, v<sub>i</sub>, a<sub>i</sub>, t<sub>i</sub>)</code> represent the current <a>internal motion</a></li>
          <li>Let <em>vel</em> be <code>v<sub>i</sub> + a<sub>i</sub> (t - t<sub>i</sub>)</code></li>
          <li>Return <em>vel</em></li>
        </ol>
      </section>

      <section>
        <h3>Compute the acceleration</h3>
        <p>
          When the user agent is required to <dfn>compute the acceleration</dfn> at a given time <code>t</code>, it must run the following steps:
        </p>
        <ol>
          <li><span class="issue">TODO: deal with initialisation conditions (readyState, Media State Vector)</span></li>
          <li>Let <code>(p<sub>i</sub>, v<sub>i</sub>, a<sub>i</sub>, t<sub>i</sub>)</code> represent the current <a>internal motion</a></li>
          <li>Return <code>a<sub>i</sub></code></li>
        </ol>
      </section>

      <section>
        <h3>Compute the motion</h3>
        <p>
          When the user agent is required to <dfn>compute the motion</dfn> at a given time <code>t</code>, it must run the following steps:
        </p>
        <ol>
          <li>Let <em>pos</em> be the result of <a title="compute the position">computing the position</a> at time <code>t</code>.</li>
          <li>Let <em>vel</em> be the result of <a title="compute the velocity">computing the velocity</a> at time <code>t</code>.</li>
          <li>Let <em>acc</em> be the result of <a title="compute the acceleration">computing the acceleration</a> at time <code>t</code>.</li>
          <li>Let <em>msv</em> be a newly constructed <a>MediaStateVector</a> object.</li>
          <li>Initialize <em>msv</em>'s <code>position</code> attribute to <em>pos</em>.</li>
          <li>Initialize <em>msv</em>'s <code>velocity</code> attribute to <em>vel</em>.</li>
          <li>Initialize <em>msv</em>'s <code>acceleration</code> attribute to <em>acc</em>.</li>
          <li>Initialize <em>msv</em>'s <code>timestamp</code> attribute to <code>t</code>.</li>
          <li>Return <em>msv</em>.</li>
        </ol>
      </section>

      <section>
        <h3>Load an online timing resource</h3>
        <p>
          The <dfn>online timing resource load algorithm</dfn> consists of the following steps:
          <br/><span class="issue">TODO</span>
        </p>
      </section>

      <section>
        <h3>Update the internal motion</h3>
        <p>
          When the user agent is required to <dfn>update the internal motion</dfn> to the provided <code>position</code>, <code>velocity</code> and <code>acceleration</code>, it must run the following steps:
          <br/><span class="issue">TODO</span>
        </p>
      </section>

      <section>
        <h3>Process an update received from the online timing service</h3>
        <p class="issue">Define what happens when a new media state vector is received from the server</p>
      </section>

      <section>
        <h3>Synchronize media state vectors</h3>
        <p class="issue">Details steps to update skew and latency (or out of scope?)</p>
      </section>
    </section>
  </body>
</html>